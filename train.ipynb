{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wazhee/Semantic-Segmentation/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0eW_TvRiO5b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms.functional as TF\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils import data\n",
        "from torchvision import transforms as T\n",
        "from torchvision import models\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1eYYJ26R1S9Ln_ExwHFBqd3rbln9qVdi4&export=download\n",
        "!unzip -qq cityscapes.zip"
      ],
      "metadata": {
        "id": "_ANItEw3iVwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Segmenter(torch.nn.Module):\n",
        "    def __init__(self, n_classes, encoder):\n",
        "        super(Segmenter, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        #self.decoder = Your code for Problem 1a goes here\n",
        "\n",
        "    def forward(self, x):\n",
        "      return None # Your code for Problem 1a goes here"
      ],
      "metadata": {
        "id": "eliKj_SjicPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CityScapesDataset(Dataset):\n",
        "  def __init__(self, images, labels, im_transform, mask_transform):\n",
        "    self.images = images\n",
        "    self.labels = labels\n",
        "    self.im_transform = im_transform\n",
        "    self.mask_transform = mask_transform\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    im = Image.open(self.images[idx])\n",
        "    mask = Image.open(self.labels[idx])\n",
        "    im = self.im_transform(im)[0:3, ...] # Transform image\n",
        "\n",
        "    # Add an extra first dimension to mask (needed for transforms), convert\n",
        "    # to LongTensor b/c values are integers, and apply transforms.\n",
        "    mask = np.asarray(mask)[None, ...] \n",
        "    mask = torch.LongTensor(mask)\n",
        "    mask = self.mask_transform(mask)\n",
        "\n",
        "    # Apply random horizontal flip to image and mask\n",
        "    if np.random.rand() > 0.5:\n",
        "      im = TF.hflip(im)\n",
        "      mask  = TF.hflip(mask)\n",
        "\n",
        "    return im, mask\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)"
      ],
      "metadata": {
        "id": "SHbzyW7AiogO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "# Make image and mask transforms.\n",
        "im_transform = [T.ToTensor()]\n",
        "im_transform.append(T.Resize((256, 256), interpolation=T.InterpolationMode.BILINEAR))\n",
        "im_transform = T.Compose(im_transform)\n",
        "\n",
        "mask_transform = T.Resize((256, 256), interpolation=T.InterpolationMode.NEAREST)\n",
        "\n",
        "def get_dataloader(im_path):\n",
        "  images = sorted(glob.glob(im_path + '/*8bit.jpg'))\n",
        "  labels = sorted(glob.glob(im_path + '/*labelIds.png'))   \n",
        "  dataset = CityScapesDataset(images, labels, im_transform, mask_transform)\n",
        "  return data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
        "\n",
        "# Create dataloaders\n",
        "train_dataloader = get_dataloader('./cityscapes/train')\n",
        "val_dataloader = get_dataloader('./cityscapes/val')"
      ],
      "metadata": {
        "id": "zDAFeoLMjKts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get features from VGG16 up through 3 downsampling (maxpool) operations.\n",
        "vgg = models.vgg16(pretrained=True);\n",
        "encoder = nn.Sequential(*(list(vgg.children())[:1])[0][0:17]);\n",
        "\n",
        "# Create model\n",
        "n_classes = 34\n",
        "model = Segmenter(n_classes, encoder);\n",
        "model.to('cuda');"
      ],
      "metadata": {
        "id": "PyPKm5ZrkUt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-4\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "num_epochs = 7\n",
        "\n",
        "# Problem 1b: Your training loop code goes here"
      ],
      "metadata": {
        "id": "Txwp1i6TkcJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 1c: Your IoU evaluation code goes here"
      ],
      "metadata": {
        "id": "Rlzt1R8skeAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 1d: Your image results code goes here"
      ],
      "metadata": {
        "id": "5d6MY5IHkv_g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}